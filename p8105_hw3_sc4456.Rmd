---
title: "p8105_hw3_sc4456"
author: "Siyan Chen"
date: "10/5/2018"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
```

# Problem 1
data import
```{r}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data(brfss_smart2010) 
modified_brfss = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response =factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))) %>% arrange(response)

```

###1
```{r}
modified_brfss %>% 
  filter(year == "2002") %>% 
  group_by(locationabbr, locationdesc) %>% 
  summarise(number = n()) %>% 
  group_by(locationabbr) %>% 
  summarise(number= n()) %>% 
  filter(number == "7") 
```
* In 2002, state CT, FL, NC were observed at 7 locations.

###2
```{r}
modified_brfss %>% 
  group_by(year, locationabbr) %>% 
  summarise(number = n()) %>% 
  ggplot(aes(x = year, y = number, color = locationabbr)) + geom_line()+
  theme_bw() + theme(legend.position = "bottom")
```

###3
```{r}
modified_brfss %>% 
  filter(locationabbr == "NY") %>% 
  filter(year == "2002" | year == "2006" | year == "2010") %>%
  select(year, locationdesc, response, sample_size) %>% 
  spread(key = response, value = sample_size) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_proption = excellent / (excellent + very_good + good + fair + poor)) %>% select(year, locationdesc, excellent_proption) %>% 
  group_by(year) %>% 
  summarise(mean = mean(excellent_proption), sd = sd(excellent_proption))
```

###4
```{r}
tidy_response_data =
modified_brfss %>% 
select(year, locationabbr, locationdesc, response, data_value) %>% 
group_by(locationabbr, year, response) %>% 
  summarise(average_proportion = mean(data_value, na.rm = TRUE)) 
  head(tidy_response_data)
  ggplot(tidy_response_data, aes(x = year, y = average_proportion, color = locationabbr)) + geom_point() + facet_grid(~response) + labs(y = "Average Proportion %")
```


# Problem 2
```{r}
library(p8105.datasets)
instacart = data.frame(instacart) %>%
  janitor::clean_names() 
instacart%>% 
  distinct(aisle_id) %>% 
  nrow()
# getting the number of distinct aisles.
 instacart %>% 
  select(aisle) %>% 
  group_by(aisle) %>% 
  summarise(number = n()) %>% 
  # the number of orders from each aisles 
  mutate(ranking = min_rank(desc(number))) %>% 
  # ranking the the data with total order number from the highest to lowest
  filter(ranking == 1)
  # obtaining the aisle which are the most items ordered from.
```
Description: This dataset contains `r ncol(instacart)` variable and `r nrow(instacart)` observation. The structure is data frame. The key variables include product_id, product_name, aisle and others. For exmaple, __?
###1 There are 134 aisles and the fresh vegetables aisle is the most items ordered from fresh vegetables.

###2 plot

```{r}
library(ggplot2)
ordered_instacart = instacart %>% 
  group_by(aisle) %>% 
  summarise(number = n()) %>% 
  as.data.frame() %>% 
  mutate(aisle = reorder(aisle, desc(number))) 
  ggplot(ordered_instacart, aes(x = aisle, y = number)) + geom_point() + theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

###3
```{r}
instacart %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle =="packaged vegetables fruits" ) %>% 
  select(aisle, product_name) %>% 
  group_by(aisle, product_name) %>% 
  summarise(number = n()) %>% 
  mutate(ranking = min_rank(desc(number))) %>% 
  # ranking from the most selled items number to the least within each aisle
  filter(ranking == 1) %>% 
# get the most popular prodcut for the interested aisles
  knitr::kable()
```

###4 

```{r}
instacart %>% 
  filter(product_name == "Pink Lady Apples"|product_name == "Coffee Ice Cream") %>% 
  select(product_name, order_hour_of_day, order_dow) %>% 
  # manipulate data
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  spread(key = order_dow, value = mean_hour) %>% 
  knitr::kable()
  
```
description: ---

# Problem 3

###1

```{r}
modified_ny_noaa = ny_noaa%>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  janitor::clean_names() 

# units?
modified_ny_noaa%>% 
  group_by(snow) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number))
# arrange the number of occuring snowfull value from the greatest to lowest and 0 is the most commonly occured
```
The Most commonly observed snowfall value is 0.

###2

```{r}
modified_ny_noaa%>% 
  mutate(month = as.numeric(month), tmax = as.numeric(tmax), tmin = as.numeric(tmin), mean_tem = (tmax + tmin)/2) %>% 
  filter(month == 1| month == 7) %>% 
  filter(!is.na(mean_tem)) %>% 
  ggplot(aes(x = year, y = mean_tem)) + geom_boxplot() + facet_grid(~month) 
```
According the the plot, July month generally has much higher temperature compared to January which makes sense. There are outliers which presents the abnormally high temperature at January and abnormally low temperature at July. There are also outliers within month for each year which suggest the variability of temperature within the same month.

###3
```{r}
modified_ny_noaa%>% 
  mutate(month = as.numeric(month), tmax = as.numeric(tmax), tmin = as.numeric(tmin)) %>%
  filter(!is.na(tmax) & !is.na(tmin)) %>% 
  ggplot(aes(x = tmax, y = tmin, color = month)) + geom_hex() 
modified_ny_noaa%>% 
  mutate(month = as.numeric(month), tmax = as.numeric(tmax), tmin = as.numeric(tmin)) %>%
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, y = snow, color = month)) + geom_boxplot()  


```













